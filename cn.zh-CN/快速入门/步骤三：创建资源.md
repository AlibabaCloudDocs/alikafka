---
keyword: [apache kafka, kafka, topic, consumergroup]
---

# 步骤三：创建资源

在使用消息队列Kafka版进行消息收发之前，您需要先在消息队列Kafka版控制台上创建资源，否则将无法通过鉴权认证及使用相关的管控运维功能。这里的资源概念是指Topic和Consumer Group。

您已根据网络环境购买并部署消息队列Kafka版服务：

-   [VPC接入](/cn.zh-CN/快速入门/步骤二：购买和部署实例/VPC接入.md)
-   [公网+VPC接入](/cn.zh-CN/快速入门/步骤二：购买和部署实例/公网+VPC接入.md)

在成功部署消息队列Kafka版服务后，您需要创建Topic和Consumer Group。

-   Topic：消息队列Kafka版里对消息进行的一级归类，例如可以创建 “Topic\_Trade” 这一主题用来识别交易类消息。使用消息队列Kafka版的第一步就是先为您的应用创建Topic。
-   Consumer Group：一类Consumer，这类Consumer通常接收并消费同一类消息，且消费逻辑一致。Consumer Group和Topic的关系是N：N，即同一个Consumer Group可以订阅多个Topic，同一个Topic也可以被多个Consumer Group订阅。

## 步骤一：创建Topic

请按照以下步骤创建Topic：

1.  登录[消息队列Kafka版控制台](https://kafka.console.aliyun.com/?spm=a2c4g.11186623.2.22.6bf72638IfKzDm)。

2.  在**概览**页面的**资源分布**区域，选择地域。

    **说明：** Topic需要在应用程序所在的地域（即所部署的ECS的所在地域）进行创建。Topic不能跨地域使用。例如Topic创建在华北2（北京）这个地域，那么消息生产端和消费端也必须运行在华北2（北京）的ECS。

3.  在**实例列表**页面，单击目标实例名称。

4.  在左侧导航栏，单击**Topic 管理**。

5.  在**Topic 管理**页面，单击**创建 Topic**。

6.  在**创建 Topic**面板，设置Topic属性，然后单击**确定**。

    ![创建Topic](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/8808912261/p278627.png)

    |参数|说明|示例|
    |--|--|--|
    |**名称**|Topic名称。|demo|
    |**描述**|Topic的简单描述。|demo test|
    |**分区数**|Topic的分区数量。|12|
    |**存储引擎**|Topic消息的存储引擎。 消息队列Kafka版支持以下两种存储引擎。

     -   **云存储**：底层接入阿里云云盘，具有低时延、高性能、持久性、高可靠等特点，采用分布式3副本机制。实例的**规格类型**为**标准版（高写版）**时，存储引擎只能为**云存储**。
    -   **Local 存储**：使用原生Kafka的ISR复制算法，采用分布式3副本机制。
|**云存储**|
    |**消息类型**|Topic消息的类型。     -   **普通消息**：默认情况下，保证相同Key的消息分布在同一个分区中，且分区内消息按照发送顺序存储。集群中出现机器宕机时，可能会造成消息乱序。当**存储引擎**选择**云存储**时，默认选择**普通消息**。
    -   **分区顺序消息**：默认情况下，保证相同Key的消息分布在同一个分区中，且分区内消息按照发送顺序存储。集群中出现机器宕机时，仍然保证分区内按照发送顺序存储。但是会出现部分分区发送消息失败，等到分区恢复后即可恢复正常。当**存储引擎**选择**Local 存储**时，默认选择**分区顺序消息**。
|**普通消息**|
    |**日志清理策略**|Topic日志的清理策略。 当**存储引擎**选择**Local 存储**时，需要配置**日志清理策略**。

 消息队列Kafka版支持以下两种日志清理策略。

     -   **Delete**：默认的消息清理策略。在磁盘容量充足的情况下，保留在最长保留时间范围内的消息；在磁盘容量不足时（一般磁盘使用率超过85%视为不足），将提前删除旧消息，以保证服务可用性。
    -   **Compact**：使用[Kafka Log Compaction日志清理策略](https://kafka.apache.org/documentation/?spm=a2c4g.11186623.2.15.1cde7bc3c8pZkD#compaction)。Log Compaction清理策略保证相同Key的消息，最新的value值一定会被保留。主要适用于系统宕机后恢复状态，系统重启后重新加载缓存等场景。例如，在使用Kafka Connect或Confluent Schema Registry时，需要使用Kafka Compact Topic存储系统状态信息或配置信息。

**说明：** Compact Topic一般只用在某些生态组件中，例如Kafka Connect或Confluent Schema Registry，其他情况的消息收发请勿为Topic设置该属性。具体信息，请参见[消息队列Kafka版Demo库](https://code.aliyun.com/alikafka/aliware-kafka-demos/tree/master)。

|**Compact**|
    |**标签**|Topic的标签。|demo|

    创建完成后，在**Topic 管理**页面的列表中显示已创建的Topic。


## 步骤二：创建Consumer Group

请按照以下步骤创建Consumer Group：

1.  登录[消息队列Kafka版控制台](https://kafka.console.aliyun.com/?spm=a2c4g.11186623.2.22.6bf72638IfKzDm)。

2.  在**概览**页面的**资源分布**区域，选择地域。

3.  在**实例列表**页面，单击目标实例名称。

4.  在左侧导航栏，单击**Group 管理**。

5.  在**Group 管理**页面，单击**创建 Group**。

6.  在**创建 Group**面板的**Group ID**文本框输入Group的名称，在**描述**文本框简要描述Group，并给Group添加标签，单击**确定**。

    创建完成后，在**Group 管理**页面的列表中显示已创建的Group。


根据网络环境使用SDK收发消息：

-   [默认接入点收发消息](/cn.zh-CN/快速入门/步骤四：使用SDK收发消息/默认接入点收发消息.md)
-   [SSL接入点PLAIN机制收发消息](/cn.zh-CN/快速入门/步骤四：使用SDK收发消息/SSL接入点PLAIN机制收发消息.md)

